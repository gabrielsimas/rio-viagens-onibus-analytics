# üöå MVP Engenharia de Dados - O Rio de Janeiro e os √înibus: Entendendo o Caos!

## ***Nome:*** **Lu√≠s Gabriel Nascimento Simas**

## ***Matr√≠cula:*** **4052025000943**

![Python](https://img.shields.io/badge/Python-3.9+-blue?style=for-the-badge&logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Container-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Airflow](https://img.shields.io/badge/Airflow-Orchestration-017CEE?style=for-the-badge&logo=apache-airflow&logoColor=white)
![dbt](https://img.shields.io/badge/dbt-Transformation-FF694B?style=for-the-badge&logo=dbt&logoColor=white)
![GCP](https://img.shields.io/badge/GCP-Cloud_Storage-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)

Este projeto constitui o MVP para a conclus√£o da P√≥s-Gradua√ß√£o em Engenharia de Dados. O objetivo √© construir uma plataforma de dados robusta (*"Modern Data Stack in a Box"*) para ingerir, processar e analisar dados de GPS, bilhetagem e frota do transporte p√∫blico da cidade do Rio de Janeiro.

---

## üèõÔ∏è Arquitetura da Solu√ß√£o

A solu√ß√£o foi desenhada seguindo o paradigma de **Data Lakehouse**, unificando a flexibilidade do Data Lake com a gest√£o de dados do Data Warehouse. Toda a infraestrutura √© containerizada via Docker, garantindo reprodutibilidade e isolamento.

![Diagrama de Arquitetura](docs/diagrama_arquitetura.png)

### Stack Tecnol√≥gica & Decis√µes Arquiteturais

Abaixo detalho as ferramentas escolhidas e a justificativa t√©cnica para cada componente:

| Componente | Ferramenta Escolhida | Justificativa T√©cnica (O "Porqu√™") |
| :--- | :--- | :--- |
| **Orquestra√ß√£o** | **Apache Airflow** | Padr√£o de mercado para gerenciamento de depend√™ncias complexas. Permite *backfilling*, retentativas autom√°ticas e monitoramento visual dos pipelines. |
| **Compute (Ingest√£o)** | **DuckDB** | Motor SQL OLAP in-process. Escolhido para substituir o Pandas na etapa de Bronze, permitindo processamento via *streaming* (baixo consumo de RAM) e convers√£o perform√°tica de CSV para Parquet. |
| **Storage** | **Google Cloud Storage** | Armazenamento de objetos escal√°vel e de baixo custo. Implementado com segrega√ß√£o f√≠sica de Buckets (Landing/Bronze) para garantir pol√≠ticas de seguran√ßa e ciclo de vida distintos. |
| **Transforma√ß√£o** | **dbt (Data Build Tool)** | Implementa a filosofia de *Analytics Engineering*. Respons√°vel pela limpeza, testes de qualidade (Data Quality) e documenta√ß√£o da linhagem dos dados. |
| **Query Engine** | **Dremio** | Atua como a camada de Lakehouse, permitindo consultas SQL de baixa lat√™ncia diretamente sobre os arquivos no Data Lake, eliminando a necessidade de c√≥pia para um Data Warehouse propriet√°rio. |
| **Formato de Arquivo** | **Parquet / Iceberg** | Formatos colunares com compress√£o (Snappy/Zstd), otimizados para leitura anal√≠tica e suporte a *schema evolution*. |

---

## üîÑ Fluxo de Dados (Pipeline)

O pipeline segue a **Arquitetura Medalh√£o** (*Medallion Architecture*) para garantir a qualidade progressiva dos dados:

![Arquitetura Medalh√£o](docs/medallion_architecture.png)

### 1. Camada Landing (Triagem)
* **Origem:** Arquivos CSV brutos extra√≠dos manualmente do BigQuery (Data Rio) e armazenados no Google Drive.
* **Processo:** Airflow orquestra o download em *chunks* para mem√≥ria local tempor√°ria.
* **Destino:** Bucket GCS `mvp-transporte-landing`.
* **Objetivo:** C√≥pia fiel da origem (*Raw*), servindo como backup imut√°vel.

### 2. Camada Bronze
* **Processo:** DuckDB l√™ os CSVs da Landing, infere schema e converte para Parquet.
* **Destino:** Bucket GCS `mvp-transporte-bronze`.
* **Objetivo:** Otimiza√ß√£o de armazenamento (compress√£o) e performance de leitura, mantendo os dados brutos hist√≥ricos.

### 3. Camada Silver (Refinada)
* **Processo:** dbt executa transforma√ß√µes SQL via Dremio.
* **A√ß√µes:** Limpeza de nulos, tipagem de dados (`String` -> `Timestamp`), renomea√ß√£o de colunas para padr√£o de neg√≥cio e desduplica√ß√£o.
* **Objetivo:** Dados confi√°veis e limpos (*"Single Source of Truth"*).

### 4. Camada Gold (Agregada)
* **Processo:** dbt modela os dados em **Esquema Estrela** (*Star Schema*).
* **Modelagem:**
    * Tabelas Fato: `fct_viagens`, `fct_telemetria`.
    * Tabelas Dimens√£o: `dim_veiculo`, `dim_calendario`.
* **Objetivo:** Dados prontos para consumo por ferramentas de BI e resposta √†s perguntas de neg√≥cio.

---

## üß™ Qualidade de Dados

A qualidade √© garantida via testes automatizados no **dbt**:
* **Unicidade:** Chaves prim√°rias (`id_viagem`) verificadas para evitar duplicatas.
* **Nulidade:** Campos cr√≠ticos n√£o podem ser nulos.
* **Regras de Neg√≥cio:** Valida√ß√£o de intervalos de datas e consist√™ncia de tempos de viagem (ex: tempo de viagem n√£o pode ser negativo).